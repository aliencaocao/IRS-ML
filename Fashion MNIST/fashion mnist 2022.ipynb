{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 22, 22, 128)       73856     \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 61952)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 256)               15859968  \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,955,210\n",
      "Trainable params: 15,955,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "235/235 [==============================] - 4s 11ms/step - loss: 0.5864 - accuracy: 0.7898 - val_loss: 0.3719 - val_accuracy: 0.8649 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.3398 - accuracy: 0.8754 - val_loss: 0.2891 - val_accuracy: 0.8938 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2783 - accuracy: 0.8959 - val_loss: 0.2509 - val_accuracy: 0.9078 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2402 - accuracy: 0.9102 - val_loss: 0.2479 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.2074 - accuracy: 0.9226 - val_loss: 0.2279 - val_accuracy: 0.9165 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.1821 - accuracy: 0.9323 - val_loss: 0.2268 - val_accuracy: 0.9171 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.1586 - accuracy: 0.9406 - val_loss: 0.2161 - val_accuracy: 0.9225 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.1400 - accuracy: 0.9482 - val_loss: 0.2197 - val_accuracy: 0.9259 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.1232 - accuracy: 0.9548 - val_loss: 0.2279 - val_accuracy: 0.9246 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.1057 - accuracy: 0.9611 - val_loss: 0.2427 - val_accuracy: 0.9239 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0967 - accuracy: 0.9644 - val_loss: 0.2442 - val_accuracy: 0.9234 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0876 - accuracy: 0.9680 - val_loss: 0.2541 - val_accuracy: 0.9261 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0773 - accuracy: 0.9716 - val_loss: 0.2547 - val_accuracy: 0.9289 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0696 - accuracy: 0.9743 - val_loss: 0.2784 - val_accuracy: 0.9264 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0640 - accuracy: 0.9766 - val_loss: 0.2650 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0580 - accuracy: 0.9791 - val_loss: 0.2766 - val_accuracy: 0.9274 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0555 - accuracy: 0.9801 - val_loss: 0.2746 - val_accuracy: 0.9291 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0508 - accuracy: 0.9811 - val_loss: 0.2731 - val_accuracy: 0.9273 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0482 - accuracy: 0.9822 - val_loss: 0.2925 - val_accuracy: 0.9258 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0445 - accuracy: 0.9841 - val_loss: 0.3130 - val_accuracy: 0.9283 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0426 - accuracy: 0.9848 - val_loss: 0.3070 - val_accuracy: 0.9298 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0408 - accuracy: 0.9851 - val_loss: 0.3065 - val_accuracy: 0.9277 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0396 - accuracy: 0.9858 - val_loss: 0.3212 - val_accuracy: 0.9274 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0380 - accuracy: 0.9862 - val_loss: 0.3128 - val_accuracy: 0.9288 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0362 - accuracy: 0.9870 - val_loss: 0.3094 - val_accuracy: 0.9289 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9871\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0366 - accuracy: 0.9871 - val_loss: 0.2992 - val_accuracy: 0.9281 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.3100 - val_accuracy: 0.9323 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0202 - accuracy: 0.9934 - val_loss: 0.3197 - val_accuracy: 0.9329 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0194 - accuracy: 0.9934 - val_loss: 0.3231 - val_accuracy: 0.9328 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0168 - accuracy: 0.9940 - val_loss: 0.3328 - val_accuracy: 0.9331 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.3327 - val_accuracy: 0.9331 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.3340 - val_accuracy: 0.9329 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.3359 - val_accuracy: 0.9321 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.3389 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.3445 - val_accuracy: 0.9335 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.3482 - val_accuracy: 0.9341 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.3472 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.3478 - val_accuracy: 0.9338 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.3491 - val_accuracy: 0.9343 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.3495 - val_accuracy: 0.9340 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.3539 - val_accuracy: 0.9337 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.3543 - val_accuracy: 0.9335 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.3583 - val_accuracy: 0.9340 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "231/235 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9963\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.3536 - val_accuracy: 0.9340 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.3550 - val_accuracy: 0.9347 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.3559 - val_accuracy: 0.9347 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.3579 - val_accuracy: 0.9345 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.3581 - val_accuracy: 0.9343 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.3588 - val_accuracy: 0.9350 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.3593 - val_accuracy: 0.9347 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.3603 - val_accuracy: 0.9344 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.3608 - val_accuracy: 0.9345 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.3616 - val_accuracy: 0.9341 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9967\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.3632 - val_accuracy: 0.9343 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.3632 - val_accuracy: 0.9343 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.3632 - val_accuracy: 0.9342 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.3632 - val_accuracy: 0.9345 - lr: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1b5308fff10>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # normalize to between 0-1\n",
    "\n",
    "# model layers\n",
    "xIn = Input((28, 28, 1))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(xIn)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='swish')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "xOut = Dense(10)(x)\n",
    "\n",
    "model = Model(inputs=xIn, outputs=xOut)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, verbose=1)\n",
    "]\n",
    "\n",
    "model.summary()\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=256, validation_data=(x_test, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3588 - accuracy: 0.9350\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.3587614595890045, 0.9350000619888306]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"mymodel.h5\")\n",
    "model.evaluate(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}